import 'dart:convert';
import 'package:smartbiztracker_new/models/manufacturing/production_recipe.dart';
import 'package:smartbiztracker_new/models/manufacturing/production_batch.dart';
import 'package:smartbiztracker_new/models/product_model.dart';
import 'package:smartbiztracker_new/services/unified_products_service.dart';
import 'package:smartbiztracker_new/services/manufacturing/manufacturing_tools_edge_cases_handler.dart';
import 'package:smartbiztracker_new/utils/app_logger.dart';
import 'package:supabase_flutter/supabase_flutter.dart';

/// Ø®Ø¯Ù…Ø© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬ ÙˆÙˆØµÙØ§Øª Ø§Ù„ØªØµÙ†ÙŠØ¹
class ProductionService {
  // Cache Ù„Ù„ÙˆØµÙØ§Øª Ù…Ø¹ Ù…Ø¯Ø© Ø§Ù†ØªÙ‡Ø§Ø¡ ØµÙ„Ø§Ø­ÙŠØ© 15 Ø¯Ù‚ÙŠÙ‚Ø©
  static final Map<String, dynamic> _cache = {};
  static const Duration _cacheDuration = Duration(minutes: 15);

  // Lazy initialization to avoid accessing Supabase.instance before initialization
  SupabaseClient get _supabase {
    try {
      return Supabase.instance.client;
    } catch (e) {
      AppLogger.error('âŒ Supabase not initialized yet in ProductionService: $e');
      throw Exception('Supabase must be initialized before using ProductionService');
    }
  }

  /// Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙØ© Ø¥Ù†ØªØ§Ø¬ Ø¬Ø¯ÙŠØ¯Ø©
  Future<int> createProductionRecipe(CreateProductionRecipeRequest request) async {
    try {
      AppLogger.info('ğŸ­ Creating production recipe for product: ${request.productId}');

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
      if (!request.isValid) {
        final errors = request.validationErrors.join(', ');
        throw Exception('Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ØµØ­ÙŠØ­Ø©: $errors');
      }

      // Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
      final recipeId = await _supabase.rpc('create_production_recipe', params: {
        'p_product_id': request.productId,
        'p_tool_id': request.toolId,
        'p_quantity_required': request.quantityRequired,
      }) as int;
      AppLogger.info('âœ… Production recipe created successfully with ID: $recipeId');

      // Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´
      _clearCache();

      return recipeId;
    } catch (e) {
      AppLogger.error('âŒ Error creating production recipe: $e');
      throw Exception('ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙØ© Ø§Ù„Ø¥Ù†ØªØ§Ø¬: $e');
    }
  }

  /// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙˆØµÙØ§Øª Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ù„Ù…Ù†ØªØ¬ Ù…Ø¹ÙŠÙ†
  Future<CompleteProductionRecipe> getProductionRecipes(int productId, {bool useCache = true}) async {
    try {
      AppLogger.info('ğŸ­ Fetching production recipes for product: $productId');

      final cacheKey = 'recipes_$productId';
      
      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒØ§Ø´
      if (useCache && _isCacheValid(cacheKey)) {
        AppLogger.info('ğŸ“¦ Using cached production recipes data');
        final cachedData = _cache[cacheKey]['data'] as List<dynamic>;
        return CompleteProductionRecipe.fromJsonList(productId, cachedData);
      }

      // Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
      final data = await _supabase.rpc('get_production_recipes', params: {
        'p_product_id': productId
      }) as List<dynamic>;
      AppLogger.info('âœ… Fetched ${data.length} production recipes');

      // Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
      _cache[cacheKey] = {
        'data': data,
        'timestamp': DateTime.now(),
      };

      return CompleteProductionRecipe.fromJsonList(productId, data);
    } catch (e) {
      AppLogger.error('âŒ Error fetching production recipes: $e');
      throw Exception('ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ ÙˆØµÙØ§Øª Ø§Ù„Ø¥Ù†ØªØ§Ø¬: $e');
    }
  }

  /// Ø¥Ù†Ø´Ø§Ø¡ Ø¯ÙØ¹Ø© Ø¥Ù†ØªØ§Ø¬ Ø¨Ø­Ø§Ù„Ø© "Ù‚ÙŠØ¯ Ø§Ù„ØªÙ†ÙÙŠØ°"
  Future<int> createProductionBatchInProgress(CreateProductionBatchRequest request) async {
    try {
      AppLogger.info('ğŸ­ Creating production batch in progress for product: ${request.productId}');

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
      if (!request.isValid) {
        final errors = request.validationErrors.join(', ');
        throw Exception('Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ØµØ­ÙŠØ­Ø©: $errors');
      }

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ ÙˆØµÙØ© Ø¥Ù†ØªØ§Ø¬
      final recipe = await getProductionRecipes(request.productId);
      if (!recipe.hasRecipes) {
        throw Exception('Ù„Ø§ ØªÙˆØ¬Ø¯ ÙˆØµÙØ© Ø¥Ù†ØªØ§Ø¬ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…Ù†ØªØ¬');
      }

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Ø§Ù„Ù…Ø®Ø²ÙˆÙ†
      if (!recipe.canProduce(request.unitsProduced)) {
        final unavailableTools = recipe.getUnavailableTools(request.unitsProduced);
        final toolNames = unavailableTools.map((t) => t.toolName).join(', ');
        throw Exception('Ù…Ø®Ø²ÙˆÙ† ØºÙŠØ± ÙƒØ§ÙÙŠ Ù…Ù† Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©: $toolNames');
      }

      // Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
      final batchId = await _supabase.rpc('create_production_batch_in_progress', params: {
        'p_product_id': request.productId,
        'p_units_produced': request.unitsProduced,
        'p_notes': request.notes,
      }) as int;
      AppLogger.info('âœ… Production batch created in progress with ID: $batchId');

      // Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´
      _clearCache();

      return batchId;
    } catch (e) {
      AppLogger.error('âŒ Error creating production batch in progress: $e');
      throw Exception('ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø¯ÙØ¹Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬: $e');
    }
  }

  /// Ø¥ÙƒÙ…Ø§Ù„ Ø¯ÙØ¹Ø© Ø¥Ù†ØªØ§Ø¬ Ù…Ø¹ Ø®ØµÙ… Ø§Ù„Ù…Ø®Ø²ÙˆÙ† Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (Ù„Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚Ø¯ÙŠÙ…)
  Future<int> completeProductionBatch(CreateProductionBatchRequest request) async {
    try {
      AppLogger.info('ğŸ­ Completing production batch for product: ${request.productId}');

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
      if (!request.isValid) {
        final errors = request.validationErrors.join(', ');
        throw Exception('Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ØµØ­ÙŠØ­Ø©: $errors');
      }

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ ÙˆØµÙØ© Ø¥Ù†ØªØ§Ø¬
      final recipe = await getProductionRecipes(request.productId);
      if (!recipe.hasRecipes) {
        throw Exception('Ù„Ø§ ØªÙˆØ¬Ø¯ ÙˆØµÙØ© Ø¥Ù†ØªØ§Ø¬ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…Ù†ØªØ¬');
      }

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Ø§Ù„Ù…Ø®Ø²ÙˆÙ†
      if (!recipe.canProduce(request.unitsProduced)) {
        final unavailableTools = recipe.getUnavailableTools(request.unitsProduced);
        final toolNames = unavailableTools.map((t) => t.toolName).join(', ');
        throw Exception('Ù…Ø®Ø²ÙˆÙ† ØºÙŠØ± ÙƒØ§ÙÙŠ Ù…Ù† Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©: $toolNames');
      }

      // Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
      final batchId = await _supabase.rpc('complete_production_batch', params: {
        'p_product_id': request.productId,
        'p_units_produced': request.unitsProduced,
        'p_notes': request.notes,
      }) as int;
      AppLogger.info('âœ… Production batch completed successfully with ID: $batchId');

      // Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´
      _clearCache();

      return batchId;
    } catch (e) {
      AppLogger.error('âŒ Error completing production batch: $e');
      throw Exception('ÙØ´Ù„ ÙÙŠ Ø¥ÙƒÙ…Ø§Ù„ Ø¯ÙØ¹Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬: $e');
    }
  }

  /// ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø¯ÙØ¹Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬
  Future<Map<String, dynamic>> updateProductionBatchStatus({
    required int batchId,
    required String newStatus,
    String? notes,
  }) async {
    try {
      AppLogger.info('ğŸ­ Updating production batch status: $batchId -> $newStatus');

      if (batchId <= 0) {
        throw Exception('Ù…Ø¹Ø±Ù Ø¯ÙØ¹Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬ ØºÙŠØ± ØµØ­ÙŠØ­');
      }

      if (!['pending', 'in_progress', 'completed', 'cancelled'].contains(newStatus)) {
        throw Exception('Ø­Ø§Ù„Ø© Ø§Ù„Ø¯ÙØ¹Ø© ØºÙŠØ± ØµØ­ÙŠØ­Ø©');
      }

      // Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
      final response = await _supabase.rpc('update_production_batch_status', params: {
        'p_batch_id': batchId,
        'p_new_status': newStatus,
        'p_notes': notes,
      }) as Map<String, dynamic>;

      if (response['success'] == true) {
        AppLogger.info('âœ… Production batch status updated successfully');

        // Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´
        _clearCache();

        return {
          'success': true,
          'batchId': response['batch_id'],
          'oldStatus': response['old_status'],
          'newStatus': response['new_status'],
          'updatedAt': response['updated_at'],
          'message': response['message'],
        };
      } else {
        throw Exception(response['error'] ?? 'ÙØ´Ù„ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø¯ÙØ¹Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬');
      }
    } catch (e) {
      AppLogger.error('âŒ Error updating production batch status: $e');
      throw Exception('ÙØ´Ù„ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø¯ÙØ¹Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬: $e');
    }
  }

  /// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¯ÙØ¹Ø§Øª Ø§Ù„Ø¥Ù†ØªØ§Ø¬
  Future<List<ProductionBatch>> getProductionBatches({
    int limit = 50,
    int offset = 0,
    bool useCache = true,
  }) async {
    try {
      AppLogger.info('ğŸ­ Fetching production batches...');

      final cacheKey = 'batches_${limit}_$offset';
      
      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒØ§Ø´
      if (useCache && _isCacheValid(cacheKey)) {
        AppLogger.info('ğŸ“¦ Using cached production batches data');
        final cachedData = _cache[cacheKey]['data'] as List<dynamic>;
        return cachedData.map((json) => ProductionBatch.fromJson(json)).toList();
      }

      // Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
      final data = await _supabase.rpc('get_production_batches', params: {
        'p_limit': limit,
        'p_offset': offset,
      }) as List<dynamic>;
      AppLogger.info('âœ… Fetched ${data.length} production batches');

      // Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
      _cache[cacheKey] = {
        'data': data,
        'timestamp': DateTime.now(),
      };

      return data.map((json) => ProductionBatch.fromJson(json)).toList();
    } catch (e) {
      AppLogger.error('âŒ Error fetching production batches: $e');
      throw Exception('ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø¯ÙØ¹Ø§Øª Ø§Ù„Ø¥Ù†ØªØ§Ø¬: $e');
    }
  }

  /// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ§Ø±ÙŠØ® Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¯ÙˆØ§Øª
  Future<List<ToolUsageHistory>> getToolUsageHistory({
    int? toolId,
    int limit = 50,
    int offset = 0,
    bool useCache = true,
  }) async {
    try {
      AppLogger.info('ğŸ­ Fetching tool usage history...');

      final cacheKey = 'usage_${toolId ?? 'all'}_${limit}_$offset';
      
      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒØ§Ø´
      if (useCache && _isCacheValid(cacheKey)) {
        AppLogger.info('ğŸ“¦ Using cached tool usage history data');
        final cachedData = _cache[cacheKey]['data'] as List<dynamic>;
        return cachedData.map((json) => ToolUsageHistory.fromJson(json)).toList();
      }

      // Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
      final data = await _supabase.rpc('get_tool_usage_history', params: {
        'p_tool_id': toolId,
        'p_limit': limit,
        'p_offset': offset,
      }) as List<dynamic>;
      AppLogger.info('âœ… Fetched ${data.length} tool usage history records');

      // Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
      _cache[cacheKey] = {
        'data': data,
        'timestamp': DateTime.now(),
      };

      return data.map((json) => ToolUsageHistory.fromJson(json)).toList();
    } catch (e) {
      AppLogger.error('âŒ Error fetching tool usage history: $e');
      throw Exception('ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ ØªØ§Ø±ÙŠØ® Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¯ÙˆØ§Øª: $e');
    }
  }

  /// Ø­Ø°Ù ÙˆØµÙØ© Ø¥Ù†ØªØ§Ø¬
  Future<bool> deleteProductionRecipe(int recipeId) async {
    try {
      AppLogger.info('ğŸ­ Deleting production recipe: $recipeId');

      await _supabase
          .from('production_recipes')
          .delete()
          .eq('id', recipeId);

      AppLogger.info('âœ… Production recipe deleted successfully');

      // Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´
      _clearCache();

      return true;
    } catch (e) {
      AppLogger.error('âŒ Error deleting production recipe: $e');
      throw Exception('ÙØ´Ù„ ÙÙŠ Ø­Ø°Ù ÙˆØµÙØ© Ø§Ù„Ø¥Ù†ØªØ§Ø¬: $e');
    }
  }

  /// Ø­Ø°Ù Ø¯ÙØ¹Ø© Ø¥Ù†ØªØ§Ø¬ Ù…Ø¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©
  Future<bool> deleteProductionBatch(int batchId) async {
    try {
      AppLogger.info('ğŸ­ Deleting production batch: $batchId');

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¯ÙØ¹Ø©
      final batchResponse = await _supabase
          .from('production_batches')
          .select('id, status, units_produced, product_id')
          .eq('id', batchId)
          .single();

      if (batchResponse.isEmpty) {
        throw Exception('Ø¯ÙØ¹Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©');
      }

      final batchStatus = batchResponse['status'] as String;

      // Ù…Ù†Ø¹ Ø­Ø°Ù Ø§Ù„Ø¯ÙØ¹Ø§Øª Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ù…Ø®Ø²ÙˆÙ†
      if (batchStatus == 'completed') {
        // ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© ÙØ­Øµ Ø¥Ø¶Ø§ÙÙŠ Ù‡Ù†Ø§ Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø®Ø²ÙˆÙ† Ø§Ù„Ù…Ø±ØªØ¨Ø·
        AppLogger.warning('âš ï¸ Attempting to delete completed production batch: $batchId');
      }

      // Ø­Ø°Ù Ø³Ø¬Ù„Ø§Øª Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ù‡Ø°Ù‡ Ø§Ù„Ø¯ÙØ¹Ø©
      await _supabase
          .from('tool_usage_history')
          .delete()
          .eq('batch_id', batchId);

      AppLogger.info('âœ… Deleted related tool usage history records');

      // Ø­Ø°Ù Ø¯ÙØ¹Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬
      await _supabase
          .from('production_batches')
          .delete()
          .eq('id', batchId);

      AppLogger.info('âœ… Production batch deleted successfully');

      // Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´
      _clearCache();

      return true;
    } catch (e) {
      AppLogger.error('âŒ Error deleting production batch: $e');
      throw Exception('ÙØ´Ù„ ÙÙŠ Ø­Ø°Ù Ø¯ÙØ¹Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬: $e');
    }
  }

  /// ØªØ­Ø¯ÙŠØ« ÙˆØµÙØ© Ø¥Ù†ØªØ§Ø¬
  Future<bool> updateProductionRecipe(int recipeId, double newQuantityRequired) async {
    try {
      AppLogger.info('ğŸ­ Updating production recipe: $recipeId -> $newQuantityRequired');

      if (newQuantityRequired <= 0) {
        throw Exception('Ø§Ù„ÙƒÙ…ÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø£ÙƒØ¨Ø± Ù…Ù† ØµÙØ±');
      }

      await _supabase
          .from('production_recipes')
          .update({'quantity_required': newQuantityRequired})
          .eq('id', recipeId);

      AppLogger.info('âœ… Production recipe updated successfully');

      // Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´
      _clearCache();

      return true;
    } catch (e) {
      AppLogger.error('âŒ Error updating production recipe: $e');
      throw Exception('ÙØ´Ù„ ÙÙŠ ØªØ­Ø¯ÙŠØ« ÙˆØµÙØ© Ø§Ù„Ø¥Ù†ØªØ§Ø¬: $e');
    }
  }

  /// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¥Ù†ØªØ§Ø¬
  Future<Map<String, dynamic>> getProductionStatistics() async {
    try {
      AppLogger.info('ğŸ“Š Calculating production statistics...');

      final batches = await getProductionBatches(limit: 1000);
      
      final stats = {
        'total_batches': batches.length,
        'completed_batches': batches.where((b) => b.status == 'completed').length,
        'pending_batches': batches.where((b) => b.status == 'pending').length,
        'in_progress_batches': batches.where((b) => b.status == 'in_progress').length,
        'cancelled_batches': batches.where((b) => b.status == 'cancelled').length,
        'total_units_produced': batches
            .where((b) => b.status == 'completed')
            .fold<double>(0, (sum, batch) => sum + batch.unitsProduced),
        'average_batch_size': batches.isNotEmpty 
            ? batches.fold<double>(0, (sum, batch) => sum + batch.unitsProduced) / batches.length
            : 0.0,
      };

      AppLogger.info('âœ… Production statistics calculated successfully');
      return stats;
    } catch (e) {
      AppLogger.error('âŒ Error calculating production statistics: $e');
      throw Exception('ÙØ´Ù„ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¥Ù†ØªØ§Ø¬: $e');
    }
  }

  /// ØªØ­Ø¯ÙŠØ« ÙƒÙ…ÙŠØ© Ø¯ÙØ¹Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ù…Ø¹ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø²ÙˆÙ†
  Future<Map<String, dynamic>> updateProductionBatchQuantity({
    required int batchId,
    required double newQuantity,
    String? notes,
  }) async {
    try {
      AppLogger.info('ğŸ­ Updating production batch quantity: $batchId -> $newQuantity');

      if (batchId <= 0) {
        throw Exception('Ù…Ø¹Ø±Ù Ø¯ÙØ¹Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬ ØºÙŠØ± ØµØ­ÙŠØ­');
      }

      if (newQuantity <= 0) {
        throw Exception('Ø§Ù„ÙƒÙ…ÙŠØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø£ÙƒØ¨Ø± Ù…Ù† ØµÙØ±');
      }

      // Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø®ØµØµØ© Ø£ÙˆÙ„Ø§Ù‹
      try {
        final response = await _supabase.rpc('update_production_batch_quantity', params: {
          'p_batch_id': batchId,
          'p_new_quantity': newQuantity,
          'p_notes': notes,
        }) as Map<String, dynamic>;

        if (response['success'] == true) {
          AppLogger.info('âœ… Production batch quantity updated successfully using custom function');

          // Log debug information if available
          if (response.containsKey('debug_info')) {
            AppLogger.info('ğŸ” Debug info: ${response['debug_info']}');
          }
          if (response.containsKey('recipes_found')) {
            AppLogger.info('ğŸ“‹ Recipes found: ${response['recipes_found']}');
          }
          if (response.containsKey('tools_updated')) {
            AppLogger.info('ğŸ”§ Tools updated: ${response['tools_updated']}');
          }

          // Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´
          _clearCache();

          return {
            'success': true,
            'batchId': response['batch_id'],
            'oldQuantity': response['old_quantity'],
            'newQuantity': response['new_quantity'],
            'quantityDifference': response['quantity_difference'],
            'recipesFound': response['recipes_found'] ?? 0,
            'toolsUpdated': response['tools_updated'] ?? 0,
            'debugInfo': response['debug_info'],
            'message': response['message'],
          };
        } else {
          // Log debug information for failed operations
          if (response.containsKey('debug_info')) {
            AppLogger.error('ğŸ” Debug info for failed operation: ${response['debug_info']}');
          }
          throw Exception(response['error'] ?? 'ÙØ´Ù„ ÙÙŠ ØªØ­Ø¯ÙŠØ« ÙƒÙ…ÙŠØ© Ø¯ÙØ¹Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬');
        }
      } catch (e) {
        // Ø¥Ø°Ø§ ÙØ´Ù„Øª Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø®ØµØµØ©ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø¯ÙŠÙ„
        AppLogger.warning('âš ï¸ Custom function failed, using alternative implementation: $e');
        return await _updateProductionBatchQuantityAlternative(batchId, newQuantity, notes);
      }
    } catch (e) {
      AppLogger.error('âŒ Error updating production batch quantity: $e');
      throw Exception('ÙØ´Ù„ ÙÙŠ ØªØ­Ø¯ÙŠØ« ÙƒÙ…ÙŠØ© Ø¯ÙØ¹Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬: $e');
    }
  }

  /// ØªÙ†ÙÙŠØ° Ø¨Ø¯ÙŠÙ„ Ù„ØªØ­Ø¯ÙŠØ« ÙƒÙ…ÙŠØ© Ø¯ÙØ¹Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©
  Future<Map<String, dynamic>> _updateProductionBatchQuantityAlternative(
    int batchId,
    double newQuantity,
    String? notes,
  ) async {
    try {
      AppLogger.info('ğŸ”„ Using alternative implementation for batch quantity update');

      // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¯ÙØ¹Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
      final batchResponse = await _supabase
          .from('production_batches')
          .select('*')
          .eq('id', batchId)
          .single();

      final oldQuantity = (batchResponse['units_produced'] as num).toDouble();
      final quantityDifference = newQuantity - oldQuantity;

      // ØªØ­Ø¯ÙŠØ« ÙƒÙ…ÙŠØ© Ø¯ÙØ¹Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬
      await _supabase
          .from('production_batches')
          .update({
            'units_produced': newQuantity,
            'notes': notes ?? batchResponse['notes'],
            'updated_at': DateTime.now().toIso8601String(),
          })
          .eq('id', batchId);

      AppLogger.info('âœ… Production batch quantity updated successfully using alternative method');

      // Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´
      _clearCache();

      return {
        'success': true,
        'batchId': batchId,
        'oldQuantity': oldQuantity,
        'newQuantity': newQuantity,
        'quantityDifference': quantityDifference,
        'message': 'ØªÙ… ØªØ­Ø¯ÙŠØ« ÙƒÙ…ÙŠØ© Ø¯ÙØ¹Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø¨Ù†Ø¬Ø§Ø­',
      };
    } catch (e) {
      AppLogger.error('âŒ Error in alternative implementation: $e');
      throw Exception('ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø¯ÙŠÙ„ Ù„ØªØ­Ø¯ÙŠØ« ÙƒÙ…ÙŠØ© Ø¯ÙØ¹Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬: $e');
    }
  }

  /// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù…Ù†ØªØ¬ ÙÙŠ Ø§Ù„Ù…Ø®Ø§Ø²Ù†
  Future<List<Map<String, dynamic>>> getProductWarehouseLocations(String productId) async {
    try {
      AppLogger.info('ğŸ“ Getting warehouse locations for product: $productId');

      if (productId.isEmpty) {
        throw Exception('Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ù†ØªØ¬ ØºÙŠØ± ØµØ­ÙŠØ­');
      }

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒØ§Ø´ Ø£ÙˆÙ„Ø§Ù‹
      final cacheKey = 'product_locations_$productId';
      if (_cache.containsKey(cacheKey)) {
        final cached = _cache[cacheKey];
        if (cached != null &&
            DateTime.now().difference(cached['timestamp']).inMinutes < 5) {
          AppLogger.info('ğŸ“‹ Using cached product locations');
          return List<Map<String, dynamic>>.from(cached['data']);
        }
      }

      // Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø®ØµØµØ© Ø£ÙˆÙ„Ø§Ù‹
      try {
        final response = await _supabase.rpc('get_product_warehouse_locations', params: {
          'p_product_id': productId,
        }) as Map<String, dynamic>;

        if (response['success'] == true) {
          final locations = List<Map<String, dynamic>>.from(response['locations'] ?? []);

          // Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
          _cache[cacheKey] = {
            'data': locations,
            'timestamp': DateTime.now(),
          };

          AppLogger.info('âœ… Retrieved ${locations.length} warehouse locations for product using custom function');
          return locations;
        } else {
          throw Exception(response['error'] ?? 'ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù…Ù†ØªØ¬');
        }
      } catch (e) {
        // Ø¥Ø°Ø§ ÙØ´Ù„Øª Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø®ØµØµØ©ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø¯ÙŠÙ„
        AppLogger.warning('âš ï¸ Custom function failed, using alternative implementation: $e');
        return await _getProductWarehouseLocationsAlternative(productId);
      }
    } catch (e) {
      AppLogger.error('âŒ Error getting product warehouse locations: $e');
      throw Exception('ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù…Ù†ØªØ¬: $e');
    }
  }

  /// ØªÙ†ÙÙŠØ° Ø¨Ø¯ÙŠÙ„ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù…Ù†ØªØ¬ ÙÙŠ Ø§Ù„Ù…Ø®Ø§Ø²Ù†
  Future<List<Map<String, dynamic>>> _getProductWarehouseLocationsAlternative(String productId) async {
    try {
      AppLogger.info('ğŸ”„ Using alternative implementation for warehouse locations');

      final response = await _supabase
          .from('warehouse_inventory')
          .select('''
            warehouse_id,
            quantity,
            minimum_stock,
            maximum_stock,
            last_updated,
            warehouses!warehouse_id (
              id,
              name,
              address,
              is_active
            )
          ''')
          .eq('product_id', productId)
          .eq('warehouses.is_active', true)
          .order('quantity', ascending: false);

      final locations = response.map<Map<String, dynamic>>((item) {
        final warehouse = item['warehouses'] as Map<String, dynamic>?;
        final quantity = item['quantity'] as int? ?? 0;
        final minimumStock = item['minimum_stock'] as int? ?? 10;

        String stockStatus;
        if (quantity == 0) {
          stockStatus = 'Ù†ÙØ¯ Ø§Ù„Ù…Ø®Ø²ÙˆÙ†';
        } else if (quantity <= minimumStock) {
          stockStatus = 'Ù…Ø®Ø²ÙˆÙ† Ù…Ù†Ø®ÙØ¶';
        } else {
          stockStatus = 'Ù…ØªÙˆÙØ±';
        }

        return {
          'warehouse_id': item['warehouse_id'],
          'warehouse_name': warehouse?['name'] ?? 'Ù…Ø®Ø²Ù† ØºÙŠØ± Ù…Ø­Ø¯Ø¯',
          'warehouse_address': warehouse?['address'] ?? '',
          'quantity': quantity,
          'minimum_stock': minimumStock,
          'maximum_stock': item['maximum_stock'],
          'stock_status': stockStatus,
          'last_updated': item['last_updated'],
        };
      }).toList();

      // Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
      final cacheKey = 'product_locations_$productId';
      _cache[cacheKey] = {
        'data': locations,
        'timestamp': DateTime.now(),
      };

      AppLogger.info('âœ… Retrieved ${locations.length} warehouse locations using alternative method');
      return locations;
    } catch (e) {
      AppLogger.error('âŒ Error in alternative warehouse locations implementation: $e');
      throw Exception('ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø¯ÙŠÙ„ Ù„Ø¬Ù„Ø¨ Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù…Ù†ØªØ¬: $e');
    }
  }

  /// Ø¥Ø¶Ø§ÙØ© Ù…Ø®Ø²ÙˆÙ† Ø§Ù„Ù…Ù†ØªØ¬ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø®Ø²Ù† Ø¨Ø¹Ø¯ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬
  Future<Map<String, dynamic>> addProductionInventoryToWarehouse({
    required String productId,
    required int quantity,
    String? warehouseId,
    int? batchId,
    String? notes,
  }) async {
    try {
      AppLogger.info('ğŸ“¦ Adding production inventory to warehouse: $productId, quantity: $quantity');

      if (productId.isEmpty || quantity <= 0) {
        throw Exception('Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ù†ØªØ¬ Ø£Ùˆ Ø§Ù„ÙƒÙ…ÙŠØ© ØºÙŠØ± ØµØ­ÙŠØ­Ø©');
      }

      // Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
      final response = await _supabase.rpc('add_production_inventory_to_warehouse', params: {
        'p_product_id': productId,
        'p_quantity': quantity,
        'p_warehouse_id': warehouseId,
        'p_batch_id': batchId,
        'p_notes': notes,
      }) as Map<String, dynamic>;

      if (response['success'] == true) {
        AppLogger.info('âœ… Production inventory added to warehouse successfully');

        // Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´
        _clearCache();

        return {
          'success': true,
          'warehouseId': response['warehouse_id'],
          'warehouseName': response['warehouse_name'],
          'productId': response['product_id'],
          'quantityAdded': response['quantity_added'],
          'quantityBefore': response['quantity_before'],
          'quantityAfter': response['quantity_after'],
          'message': response['message'],
        };
      } else {
        throw Exception(response['error'] ?? 'ÙØ´Ù„ ÙÙŠ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø®Ø²ÙˆÙ†');
      }
    } catch (e) {
      AppLogger.error('âŒ Error adding production inventory to warehouse: $e');
      throw Exception('ÙØ´Ù„ ÙÙŠ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø®Ø²ÙˆÙ†: $e');
    }
  }

  /// Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ÙƒØ§Ø´
  bool _isCacheValid(String key, {int? maxAgeMinutes}) {
    if (!_cache.containsKey(key)) return false;

    final cacheEntry = _cache[key];
    final timestamp = cacheEntry['timestamp'] as DateTime;

    final maxAge = maxAgeMinutes != null
        ? Duration(minutes: maxAgeMinutes)
        : _cacheDuration;

    return DateTime.now().difference(timestamp) < maxAge;
  }

  /// Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´
  void _clearCache() {
    _cache.clear();
    AppLogger.info('ğŸ—‘ï¸ Production service cache cleared');
  }

  /// ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª API
  Future<void> _updateProductDataInDatabase(int productId, ProductModel apiProduct) async {
    try {
      AppLogger.info('ğŸ’¾ Updating product data in database for product: $productId');

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ø¯ÙŠØ«
      if (apiProduct.name.isEmpty) {
        AppLogger.warning('âš ï¸ Invalid product name, skipping database update');
        return;
      }

      if (apiProduct.quantity < 0) {
        AppLogger.warning('âš ï¸ Invalid product quantity (${apiProduct.quantity}), skipping database update');
        return;
      }

      // ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬ ÙÙŠ Ø¬Ø¯ÙˆÙ„ products
      await _supabase.from('products').upsert({
        'id': productId.toString(),
        'name': apiProduct.name.trim(),
        'quantity': apiProduct.quantity,
        'price': apiProduct.price,
        'description': apiProduct.description?.trim() ?? '',
        'category': apiProduct.category?.trim() ?? '',
        'sku': apiProduct.sku?.trim() ?? '',
        'image_url': apiProduct.imageUrl?.trim(),
        'active': apiProduct.isActive, // Fixed: use 'active' instead of 'is_active' to match database schema
        'updated_at': DateTime.now().toIso8601String(),
        'supplier': apiProduct.supplier?.trim(),
        'manufacturing_cost': apiProduct.manufacturingCost,
        'reorder_point': apiProduct.reorderPoint,
        'minimum_stock': apiProduct.minimumStock,
      }).timeout(
        const Duration(seconds: 5),
        onTimeout: () {
          AppLogger.warning('â° Database update timeout for product $productId');
          throw Exception('Database update timeout');
        },
      );

      AppLogger.info('âœ… Product data updated successfully in database');
    } catch (e) {
      AppLogger.error('âŒ Error updating product data in database: $e');
      // Ù„Ø§ Ù†Ø±Ù…ÙŠ Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ù‡Ù†Ø§ Ù„Ø£Ù† Ù‡Ø°Ø§ Ù„ÙŠØ³ Ø£Ù…Ø±Ø§Ù‹ Ø­Ø±Ø¬Ø§Ù‹
      // ÙˆÙ„ÙƒÙ† Ù†Ø³Ø¬Ù„ Ø§Ù„Ø®Ø·Ø£ Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©
    }
  }

  /// Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´ ÙŠØ¯ÙˆÙŠØ§Ù‹
  void clearCache() {
    _clearCache();
  }

  /// Ù…Ø³Ø­ ÙƒØ§Ø´ ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ù„Ø¯ÙØ¹Ø© Ù…Ø¹ÙŠÙ†Ø©
  void clearToolAnalyticsCache(int batchId) {
    final cacheKey = 'tool_analytics_$batchId';
    _cache.remove(cacheKey);
    AppLogger.info('ğŸ—‘ï¸ Cleared tool analytics cache for batch: $batchId');
  }

  /// Ø¥Ø¬Ø¨Ø§Ø± ØªØ­Ø¯ÙŠØ« ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø£Ø¯ÙˆØ§Øª (Ø¨Ø¯ÙˆÙ† ÙƒØ§Ø´)
  Future<List<ToolUsageAnalytics>> forceRefreshToolAnalytics(int batchId) async {
    clearToolAnalyticsCache(batchId);
    return await getToolUsageAnalytics(batchId);
  }

  /// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ù†ØªØ¬ Ø¨Ø§Ù„Ù…Ø¹Ø±Ù
  /// ÙŠØ³ØªØ®Ø¯Ù… UnifiedProductsService Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„ÙƒØ§Ù…Ù„Ø©
  Future<ProductModel?> getProductById(int productId) async {
    try {
      AppLogger.info('ğŸ” Fetching product details for ID: $productId');

      final cacheKey = 'product_$productId';

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒØ§Ø´
      if (_isCacheValid(cacheKey)) {
        AppLogger.info('ğŸ“¦ Using cached product data for ID: $productId');
        final cachedData = _cache[cacheKey]['data'] as Map<String, dynamic>;
        return ProductModel.fromJson(cachedData);
      }

      // Ø§Ø³ØªØ®Ø¯Ø§Ù… UnifiedProductsService Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†ØªØ¬
      final unifiedService = UnifiedProductsService();
      final product = await unifiedService.getProductById(productId.toString());

      if (product != null) {
        // Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
        _cache[cacheKey] = {
          'data': product.toJson(),
          'timestamp': DateTime.now(),
        };

        AppLogger.info('âœ… Product found: ${product.name}');
        return product;
      } else {
        AppLogger.warning('âš ï¸ Product not found for ID: $productId');
        return null;
      }
    } catch (e) {
      AppLogger.error('âŒ Error fetching product by ID $productId: $e');
      return null;
    }
  }

  /// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ø¯Ø© Ù…Ù†ØªØ¬Ø§Øª Ø¨Ù…Ø¹Ø±ÙØ§ØªÙ‡Ø§
  /// Ù…ÙÙŠØ¯ Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ù†ØªØ¬Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø¨ÙƒÙØ§Ø¡Ø©
  Future<Map<int, ProductModel>> getProductsByIds(List<int> productIds) async {
    try {
      AppLogger.info('ğŸ” Fetching ${productIds.length} products by IDs');

      final results = <int, ProductModel>{};
      final uncachedIds = <int>[];

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒØ§Ø´ Ø£ÙˆÙ„Ø§Ù‹
      for (final id in productIds) {
        final cacheKey = 'product_$id';
        if (_isCacheValid(cacheKey)) {
          final cachedData = _cache[cacheKey]['data'] as Map<String, dynamic>;
          results[id] = ProductModel.fromJson(cachedData);
        } else {
          uncachedIds.add(id);
        }
      }

      // Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ Ø§Ù„ÙƒØ§Ø´
      if (uncachedIds.isNotEmpty) {
        final unifiedService = UnifiedProductsService();

        for (final id in uncachedIds) {
          final product = await unifiedService.getProductById(id.toString());
          if (product != null) {
            results[id] = product;

            // Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
            final cacheKey = 'product_$id';
            _cache[cacheKey] = {
              'data': product.toJson(),
              'timestamp': DateTime.now(),
            };
          }
        }
      }

      AppLogger.info('âœ… Fetched ${results.length} products successfully');
      return results;
    } catch (e) {
      AppLogger.error('âŒ Error fetching products by IDs: $e');
      return {};
    }
  }

  /// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØµÙ†ÙŠØ¹ Ù„Ø¯ÙØ¹Ø© Ø¥Ù†ØªØ§Ø¬
  Future<List<ToolUsageAnalytics>> getToolUsageAnalytics(int batchId) async {
    try {
      AppLogger.info('ğŸ“Š Fetching tool usage analytics for batch: $batchId with enhanced remaining stock calculation');

      final cacheKey = 'tool_analytics_$batchId';

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒØ§Ø´ (Ù…Ø¹ ØªÙ‚Ù„ÙŠÙ„ Ù…Ø¯Ø© Ø§Ù„ÙƒØ§Ø´ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø«Ø©)
      if (_cache.containsKey(cacheKey)) {
        final cached = _cache[cacheKey];
        if (cached != null &&
            DateTime.now().difference(cached['timestamp']).inMinutes < 2) { // ØªÙ‚Ù„ÙŠÙ„ Ù…Ø¯Ø© Ø§Ù„ÙƒØ§Ø´ Ø¥Ù„Ù‰ Ø¯Ù‚ÙŠÙ‚ØªÙŠÙ†
          AppLogger.info('ğŸ“¦ Using cached tool analytics data');
          final cachedData = cached['data'] as List<dynamic>;
          return cachedData.map((json) => ToolUsageAnalytics.fromJson(json)).toList();
        }
      }

      // Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ù…Ø¹ Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø­Ø³Ù†
      final response = await _supabase.rpc('get_batch_tool_usage_analytics', params: {
        'p_batch_id': batchId,
      }) as List<dynamic>;

      AppLogger.info('ğŸ“Š Raw analytics response: ${response.length} tools found');

      final analytics = response
          .map((json) {
            final data = json as Map<String, dynamic>;
            AppLogger.info('ğŸ”§ Tool: ${data['tool_name']}, Remaining Stock: ${data['remaining_stock']}, Used Per Unit: ${data['quantity_used_per_unit']}');
            return ToolUsageAnalytics.fromJson(data);
          })
          .toList();

      // ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠØ©
      final List<ToolUsageAnalytics> sanitizedAnalytics = analytics
          .map((analytic) => ManufacturingToolsEdgeCasesHandler.sanitizeToolAnalytics(analytic))
          .toList();

      // Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
      _cache[cacheKey] = {
        'data': response,
        'timestamp': DateTime.now(),
      };

      AppLogger.info('âœ… Fetched ${sanitizedAnalytics.length} tool usage analytics with enhanced remaining stock calculation');
      return sanitizedAnalytics;
    } catch (e) {
      AppLogger.error('âŒ Error fetching tool usage analytics: $e');
      return [];
    }
  }

  /// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ ÙØ¬ÙˆØ© Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ø­Ø¯ÙŠØ«Ø© Ù…Ù† API
  Future<ProductionGapAnalysis?> getProductionGapAnalysis(int productId, int batchId) async {
    try {
      AppLogger.info('ğŸ“ˆ Fetching production gap analysis for product: $productId, batch: $batchId');

      final cacheKey = 'gap_analysis_${productId}_$batchId';

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒØ§Ø´ (Ù…Ø¹ Ù…Ø¯Ø© Ø§Ù†ØªÙ‡Ø§Ø¡ ØµÙ„Ø§Ø­ÙŠØ© Ø£Ù‚ØµØ± Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø¯ÙŠØ«Ø©)
      if (_isCacheValid(cacheKey, maxAgeMinutes: 5)) {
        AppLogger.info('ğŸ“¦ Using cached gap analysis data');
        final cachedData = _cache[cacheKey]['data'] as Map<String, dynamic>;
        return ProductionGapAnalysis.fromJson(cachedData);
      }

      // Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ø­Ø¯ÙŠØ«Ø© Ù…Ù† API Ø£ÙˆÙ„Ø§Ù‹ Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
      ProductModel? apiProduct;
      try {
        AppLogger.info('ğŸ”„ Fetching fresh product data from API for product: $productId');
        apiProduct = await getProductById(productId).timeout(
          const Duration(seconds: 10),
          onTimeout: () {
            AppLogger.warning('â° API timeout for product $productId, using database fallback');
            return null;
          },
        );

        // ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø°Ø§ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª API
        if (apiProduct != null) {
          AppLogger.info('âœ… Fresh product data found: ${apiProduct.name}, quantity: ${apiProduct.quantity}');
          await _updateProductDataInDatabase(productId, apiProduct);
        } else {
          AppLogger.warning('âš ï¸ No API product data found for product: $productId, using database fallback');
        }
      } catch (e) {
        AppLogger.error('âŒ Error fetching API product data for product $productId: $e');
        AppLogger.info('ğŸ”„ Continuing with database fallback for gap analysis');
        apiProduct = null;
      }

      // Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ¬ÙˆØ© (Ø³ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø«Ø©)
      final response = await _supabase.rpc('get_production_gap_analysis', params: {
        'p_product_id': productId,
        'p_batch_id': batchId,
      });

      if (response == null) {
        AppLogger.warning('âš ï¸ No gap analysis data found');
        return null;
      }

      // ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø¥Ù„Ù‰ Map Ø¥Ø°Ø§ ÙƒØ§Ù†Øª JSONB
      Map<String, dynamic> responseMap;
      if (response is Map<String, dynamic>) {
        responseMap = response;
      } else if (response is String) {
        // Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù†Øµ JSONØŒ Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„Ù‡Ø§
        responseMap = jsonDecode(response) as Map<String, dynamic>;
      } else {
        // Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† Ù†ÙˆØ¹ Ø¢Ø®Ø±ØŒ Ø­Ø§ÙˆÙ„ ØªØ­ÙˆÙŠÙ„Ù‡Ø§
        responseMap = Map<String, dynamic>.from(response as Map);
      }

      // Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙ†Ø§ Ø¨ÙŠØ§Ù†Ø§Øª API Ø­Ø¯ÙŠØ«Ø©ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙƒÙ…ÙŠØ© Ù…Ù† API ÙƒÙ‡Ø¯Ù
      if (apiProduct != null && apiProduct.quantity > 0) {
        AppLogger.info('ğŸ¯ Using API product quantity as target: ${apiProduct.quantity}');
        responseMap['target_quantity'] = apiProduct.quantity.toDouble();

        // Ø¥Ø¹Ø§Ø¯Ø© Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯
        final currentProduction = (responseMap['current_production'] as num).toDouble();
        final newTargetQuantity = apiProduct.quantity.toDouble();

        responseMap['remaining_pieces'] = newTargetQuantity - currentProduction;
        responseMap['completion_percentage'] = newTargetQuantity > 0
            ? (currentProduction / newTargetQuantity) * 100
            : 0.0;
        responseMap['is_over_produced'] = currentProduction > newTargetQuantity;
        responseMap['is_completed'] = currentProduction >= newTargetQuantity;

        AppLogger.info('ğŸ“Š Updated gap analysis with API target - Target: $newTargetQuantity, Current: $currentProduction, Remaining: ${responseMap['remaining_pieces']}');
      }

      final gapAnalysis = ProductionGapAnalysis.fromJson(responseMap);

      // Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
      _cache[cacheKey] = {
        'data': responseMap,
        'timestamp': DateTime.now(),
      };

      // Ø¥Ø°Ø§ ØªÙ… ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬ Ù…Ù† APIØŒ Ù‚Ù… Ø¨Ù…Ø³Ø­ ÙƒØ§Ø´ ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ù„Ø¶Ù…Ø§Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
      if (apiProduct != null) {
        final toolAnalyticsCacheKey = 'tool_analytics_$batchId';
        if (_cache.containsKey(toolAnalyticsCacheKey)) {
          _cache.remove(toolAnalyticsCacheKey);
          AppLogger.info('ğŸ—‘ï¸ Invalidated tool analytics cache due to API product update');
        }
      }

      AppLogger.info('âœ… Production gap analysis loaded successfully with ${apiProduct != null ? 'API' : 'database'} target data');
      return gapAnalysis;
    } catch (e) {
      AppLogger.error('âŒ Error fetching production gap analysis: $e');
      return null;
    }
  }

  /// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ
  Future<RequiredToolsForecast?> getRequiredToolsForecast(int productId, double remainingPieces) async {
    try {
      AppLogger.info('ğŸ”® Fetching required tools forecast for product: $productId, remaining: $remainingPieces');

      final cacheKey = 'tools_forecast_${productId}_${remainingPieces.toStringAsFixed(2)}';

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒØ§Ø´
      if (_isCacheValid(cacheKey)) {
        AppLogger.info('ğŸ“¦ Using cached tools forecast data');
        final cachedData = _cache[cacheKey]['data'] as Map<String, dynamic>;
        return RequiredToolsForecast.fromJson(cachedData);
      }

      // Handle edge case: zero remaining pieces
      if (remainingPieces <= 0) {
        AppLogger.info('ğŸ”„ Zero remaining pieces - returning completed forecast');
        final completedForecast = RequiredToolsForecast(
          productId: productId,
          remainingPieces: 0.0,
          requiredTools: [],
          canCompleteProduction: true,
          unavailableTools: [],
          totalCost: 0.0,
        );

        // Cache the result
        _cache[cacheKey] = {
          'data': completedForecast.toJson(),
          'timestamp': DateTime.now(),
        };

        return completedForecast;
      }

      // Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ø£Ø¯ÙˆØ§Øª
      final response = await _supabase.rpc('get_required_tools_forecast', params: {
        'p_product_id': productId,
        'p_remaining_pieces': remainingPieces,
      });

      // Handle different response types (Map or String)
      Map<String, dynamic> responseMap;
      if (response is Map<String, dynamic>) {
        responseMap = response;
      } else if (response is String) {
        try {
          responseMap = jsonDecode(response) as Map<String, dynamic>;
        } catch (e) {
          AppLogger.error('âŒ Failed to parse JSON response: $e');
          return null;
        }
      } else if (response != null) {
        responseMap = Map<String, dynamic>.from(response as Map);
      } else {
        AppLogger.warning('âš ï¸ Null response from database function');
        return null;
      }

      if (responseMap['success'] != true) {
        AppLogger.warning('âš ï¸ Database function returned error: ${responseMap['error'] ?? 'Unknown error'}');
        return null;
      }

      // Extract and validate the forecast data with proper structure for RequiredToolsForecast model
      final forecastData = {
        'product_id': responseMap['product_id'] ?? productId,
        'remaining_pieces': (responseMap['remaining_pieces'] as num?)?.toDouble() ?? remainingPieces,
        'required_tools': responseMap['required_tools'] ?? [],
        'can_complete_production': responseMap['can_complete_production'] ?? false,
        'unavailable_tools': responseMap['unavailable_tools'] ?? [],
        'total_cost': (responseMap['total_cost'] as num?)?.toDouble() ?? 0.0,
      };

      // Validate required_tools structure
      final requiredToolsList = forecastData['required_tools'] as List<dynamic>;
      AppLogger.info('ğŸ“Š Processing ${requiredToolsList.length} required tools');

      // Log detailed tool information for debugging
      for (int i = 0; i < requiredToolsList.length; i++) {
        final tool = requiredToolsList[i] as Map<String, dynamic>;
        AppLogger.info('ğŸ”§ Tool ${i + 1}: ${tool['tool_name']} - Required: ${tool['total_quantity_needed']}, Available: ${tool['available_stock']}, Status: ${tool['availability_status']}');
      }

      final forecast = RequiredToolsForecast.fromJson(forecastData);

      // Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
      _cache[cacheKey] = {
        'data': forecastData,
        'timestamp': DateTime.now(),
      };

      AppLogger.info('âœ… Fetched tools forecast: ${forecast.toolsCount} tools, can complete: ${forecast.canCompleteProduction}, total cost: ${forecast.totalCost.toStringAsFixed(2)}');
      return forecast;
    } catch (e, stackTrace) {
      AppLogger.error('âŒ Error fetching required tools forecast: $e');
      AppLogger.error('Stack trace: $stackTrace');
      return null;
    }
  }

  /// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ§Ø±ÙŠØ® Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯Ø§Ø© Ù…Ø¹ÙŠÙ†Ø©
  Future<List<ToolUsageEntry>> getSpecificToolUsageHistory(int toolId, {int? batchId, int limit = 50}) async {
    try {
      AppLogger.info('ğŸ“œ Fetching tool usage history for tool: $toolId');

      final cacheKey = 'tool_history_${toolId}_${batchId ?? 'all'}_$limit';

      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒØ§Ø´
      if (_isCacheValid(cacheKey)) {
        AppLogger.info('ğŸ“¦ Using cached tool usage history');
        final cachedData = _cache[cacheKey]['data'] as List<dynamic>;
        return cachedData.map((json) => ToolUsageEntry.fromJson(json)).toList();
      }

      // Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
      final response = await _supabase.rpc('get_tool_usage_history', params: {
        'p_tool_id': toolId,
        'p_batch_id': batchId,
        'p_limit': limit,
      }) as List<dynamic>;

      final history = response
          .map((json) => ToolUsageEntry.fromJson(json as Map<String, dynamic>))
          .toList();

      // Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
      _cache[cacheKey] = {
        'data': response,
        'timestamp': DateTime.now(),
      };

      AppLogger.info('âœ… Fetched ${history.length} tool usage history entries');
      return history;
    } catch (e) {
      AppLogger.error('âŒ Error fetching tool usage history: $e');
      return [];
    }
  }
}
